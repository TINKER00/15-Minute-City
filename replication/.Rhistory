main_path <- "/Users/arianna/Dropbox (Personal)/SenseableCityLab/15_minute_city/_git/15-Minute-City/replication"  # User should replace this with the path to the 'replication' folder
## ==========================
## 1. Loading Libraries
## ==========================
# Function to check and install any missing packages
install_and_load <- function(package) {
if (!require(package, character.only = TRUE)) {
cat(sprintf("Installing package: '%s'\n", package))
install.packages(package, dependencies = TRUE)
library(package, character.only = TRUE)
} else {
cat(sprintf("Package '%s' is already installed.\n", package))
}
}
# List of required packages
packages <- c("lfe", "ggplot2", "tidyverse", "stargazer", "haven", "fixest", "tmap",
"sf", "rosm", "prettymapr", "ggpubr", "tmaptools", "grid",
"gridExtra", "osmdata", "reshape2", "repr", "stringr", "ggrepel", "OpenStreetMap", "spatstat")
# Apply the function to each package
invisible(sapply(packages, install_and_load))
# Install OpenStreetMap
if (!require(devtools)) install.packages("devtools")
devtools::install_github("ifellows/ROSM/OpenStreetMap")
# Set working directory to main path
setwd(main_path)
cbgs_data_path <- file.path(main_path, "data", "clean", "outcomes_blckgrp_clean_popweighted.csv")
urban_areas_data_path <- file.path(main_path, "data", "clean", "outcomes_urb_clean_popweighted.csv")
urban_areas_geo_path <- file.path(main_path, "data", "raw", "census_urbanareas_2021", "tl_2021_us_uac10", "tl_2021_us_uac10.shp")
# Read the datasets.
cbgs <- read.csv(cbgs_data_path)
urban_areas <- read.csv(urban_areas_data_path)
# Load urban areas geographical data and rename a column for merging
urban_areas_geo <- st_read(urban_areas_geo_path, stringsAsFactors = FALSE) %>% rename(urb=UACE10)
urban_areas_geo_path <- file.path(main_path, "data", "clean", "census_urbanareas_2021", "tl_2021_us_uac10", "tl_2021_us_uac10.shp")
urban_areas_geo <- st_read(urban_areas_geo_path, stringsAsFactors = FALSE) %>% rename(urb=UACE10)
# Reading the dataset of block groups and renaming columns
cbgs  <- cbgs %>% rename(
density_hu_acre = epa_D1A,
total_pop = idx_total_population,
density_pop_acre = epa_D1B,
median_hh_income = cs_b19013e1,
density_road = epa_D3A
)
cbgs$pct_ed_ba_plus <- 100 * (cbgs$cs_b15003e22 + cbgs$cs_b15003e23 + cbgs$cs_b15003e24 + cbgs$cs_b15003e25) / cbgs$cs_b15003e1
urban_areas  <- urban_areas %>% rename(
density_hu_acre = epa_D1A,
total_pop = cs_b01001e1_urb,
density_pop_acre = epa_D1B,
median_hh_income = cs_b19013e1,
density_road = epa_D3A
)
urban_areas$pct_ed_ba_plus <- 100 * (urban_areas$cs_b15003e22 + urban_areas$cs_b15003e23 + urban_areas$cs_b15003e24 + urban_areas$cs_b15003e25) / urban_areas$cs_b15003e1
urban_areas_geo$urb <- as.numeric(urban_areas_geo$urb)
urban_areas <- st_as_sf(urban_areas %>% left_join(urban_areas_geo, by='urb'))
# Extract urban area and state codes from the urban area name.
urban_areas$Urban.Area  <- as.character(urban_areas$urb_name) %>% purrr::map(function (n) toString(
unlist(strsplit(strsplit(n,", ")[[1]][[1]],"--")[[1]][[1]])
))
urban_areas$State.Code <- as.character(urban_areas$urb_name) %>% purrr::map(function (n) toString(
unlist(strsplit(strsplit(n,", ")[[1]][[-1]],"--")[[1]][[1]])
))
urban_areas$State.Code <- as.character(urban_areas$State.Code)
urban_areas$State.Code <- as.factor(urban_areas$State.Code)
urban_areas$ua <- str_c(urban_areas$Urban.Area, urban_areas$State.Code, sep=", ")
# Join urban area data to block groups dataset and extract state codes from urban area name.
cbgs <- cbgs %>% left_join(urban_areas %>% select(urb,Urban.Area))
cbgs$State.Code <- as.character(cbgs$urb_name) %>% purrr::map(function (n) toString(
unlist(strsplit(strsplit(n,", ")[[1]][[-1]],"--")[[1]][[1]])
))
cbgs$State.Code <- as.character(cbgs$State.Code)
cbgs$State.Code <- as.factor(cbgs$State.Code)
cbgs$ua <- str_c(cbgs$Urban.Area, cbgs$State.Code, sep=", ")
# Multiply usage percentages and accessibility indexes by 100 to convert to percentage format.
cbgs$usage_pct_all_cats_home_bg_based <- 100 * cbgs$usage_pct_all_cats_home_bg_based
cbgs$access_idx_crosscity_wt <- 100 * cbgs$access_idx_crosscity_wt
urban_areas$usage_pct_all_cats_home_bg_based <- 100 * urban_areas$usage_pct_all_cats_home_bg_based
urban_areas$access_idx_crosscity_wt <- 100 * urban_areas$access_idx_crosscity_wt
# Create log transformed variables for population size visualization.
urban_areas$POPLOG <-log1p(urban_areas$total_pop)
urban_areas$POPSIZE <-'^'(urban_areas$POPLOG,7)
# Set API key for Mapbox and base URL for map tiles.
apiKey <- paste0("?access_token=", "pk.eyJ1IjoidGFiYmlhc292IiwiYSI6ImNqYXJtaDZvcTRnb2UycXBkYzJ4OG42bmkifQ.ASyqoW1tK4cqSNsbyUIN7Q")
baseUrl <- "https://api.mapbox.com/styles/v1/tabbiasov/cl3ag5eyo003y14p0xmjxpglh/tiles/256/{z}/{x}/{y}"
bbox_us = bb(c(c(-124.848974, 24.396308),c(-66.885444, 49.384358)), current.projection = 4326, projection = 3857)
# Fetch base map for the US.
basemap_us <- read_osm(bbox_us, type=paste0(baseUrl,apiKey))
# Create a bar chart dataset for the top 15 urban areas based on usage.
bardata <- urban_areas %>% st_drop_geometry() %>% slice_max(usage_pct_all_cats_home_bg_based, n = 15)
# Plotting a horizontal bar chart for the top 15 urban areas.
usage_msas_barchart <- ggplot(bardata, aes(x = reorder(factor(ua), usage_pct_all_cats_home_bg_based), y = usage_pct_all_cats_home_bg_based)) +
geom_bar(stat = "identity", width = 0.8, position = position_dodge(width = 0.9), fill="#bac5c3", show.legend=FALSE) +
coord_flip() +
labs(y = "Average Usage (% trips)", x = "") +
theme_bw() +
theme(legend.position="bottom", legend.justification="right", legend.direction = "horizontal", legend.text=element_text(size=10, color="#666666"), text=element_text(size=11,  family="Helvetica"), axis.text.y = element_text(face=600, color="black",size=10), axis.text.x = element_text(size=9), plot.title=element_text(family='Helvetica', size=11), plot.margin = margin(t = 24, r = 16, b = 4, l = 0, unit = "points"), legend.margin=margin(0,10,0,0), legend.key.width = unit(2.66,"line"), legend.key.height = unit(0.5,"line"))
# Specify names of select major metropolitan areas for mapping.
map_msas <- c('New York--Newark, NY--NJ--CT', 'San Francisco--Oakland, CA', 'Philadelphia, PA--NJ--DE--MD', 'Los Angeles--Long Beach--Anaheim, CA', 'Chicago, IL--IN', 'Champaign, IL', 'Murfreesboro, TN')
# Create a map visualization for usage across urban areas.
us_map_usage <-
tm_shape(basemap_us) +
tm_rgb() +
tm_shape(urban_areas) +
tm_symbols("usage_pct_all_cats_home_bg_based", size="POPSIZE",  title.size = 'Population (m)', n=3, sizes.legend.labels = c('1.1','4.6','11.5',"22.7"), legend.col.show = TRUE,  alpha=0.9, scale=1.1, border.lwd = NA, palette=c("#f25d46","#e4ca23","#096f53"), breaks = c(0,10,12,14,16,18,20,25,30,40,50)) +
tm_shape(urban_areas %>% filter(urb_name %in% map_msas)) +
tm_text(text = "Urban.Area", fontfamily='Helvetica', size=0.65, xmod=1.2, ymod = 0.3) +
tm_legend(outside = TRUE, outside.position = c("bottom"), stack = "horizontal", legend.title.size = 1.15, legend.text.size = 0.85, legend.text.color = "#666666", legend.title.fontfamily='Helvetica', legend.text.fontfamily='Helvetica', legend.outside.size = 0.5) +
tm_layout(fontfamily='Helvetica', legend.only = FALSE, legend.show=FALSE, main.title.fontfamily='Helvetica', main.title = "Urban Areas in United States", main.title.size = 1)
# Create a legend for the usage map.
us_map_usage_legend <-
tm_shape(basemap_us) +
tm_rgb() +
tm_shape(urban_areas) +
tm_symbols("usage_pct_all_cats_home_bg_based", size="POPSIZE",  title.size = 'Population (m)', n=3, sizes.legend.labels = c('1.1','4.6','11.5',"22.7"), legend.col.show = FALSE,  alpha=0.9, scale=1.1, border.lwd = NA, palette=c("#f25d46","#e4ca23","#096f53"), breaks = c(0,10,12,14,16,18,20,25,30,40,50)) +
tm_legend(outside = TRUE, outside.position = c("bottom"), stack = "horizontal", legend.title.size = 1.15, legend.text.size = 0.85, legend.text.color = "#666666", legend.title.fontfamily='Helvetica', legend.text.fontfamily='Helvetica', legend.outside.size = 0.5) +
tm_layout(fontfamily='Helvetica', main.title.fontfamily='Helvetica', main.title = "Urban Areas in United States", main.title.size = 1, legend.only = TRUE, legend.show=TRUE)
colfunc <- colorRampPalette(c("#f25d46","#e4ca23","#096f53"))
colors <- c(colfunc(10))
# Create a bar chart with a color legend for select major metropolitan areas.
usage_msas_barchart_with_legend <- ggplot(filter(urban_areas, urb_name %in% map_msas), aes(x = reorder(factor(ua), usage_pct_all_cats_home_bg_based), y = usage_pct_all_cats_home_bg_based)) +
geom_bar(stat = "identity", width = 0.8, position = position_dodge(width = 0.9), aes(fill=usage_pct_all_cats_home_bg_based), show.legend=TRUE) +
binned_scale(aesthetics = "fill", scale_name = "stepsn",  palette = function(x) colors, breaks = c(10,12,14,16,18,20,25,30,40), limits = c(0, 50), show.limits = TRUE,  guide = "colorsteps", name = "15m Usage (% trips)\n") +
coord_flip() +
labs(y = "Average Usage (% trips)", x = "") +
theme_bw() +
theme(legend.position="bottom", legend.justification="right", legend.direction = "horizontal", legend.text=element_text(size=10, color="#666666"), text=element_text(size=11,  family="Helvetica"), axis.text.y = element_text(face=600, color="black",size=11), axis.text.x = element_text(size=11), plot.title=element_text(family='Helvetica', size=11), plot.margin = margin(t = 24, r = 16, b = 4, l = 0, unit = "points"), legend.margin=margin(0,10,0,0), legend.key.width = unit(2.66,"line"), legend.key.height = unit(0.5,"line"))
# Extract the legend from the bar chart.
legend <- get_legend(usage_msas_barchart_with_legend)
# Import the `stat_ecdf_weighted` function for the weighted empirical cumulative distribution function.
source("https://raw.githubusercontent.com/NicolasWoloszko/stat_ecdf_weighted/master/stat_ecdf_weighted.R")
# Plotting an empirical cumulative distribution function.
cdf_plot <- ggplot(cbgs, aes(x=usage_pct_all_cats_home_bg_based, weight=total_pop)) +
stat_ecdf(geom = "step", size=0.66, color='#096f53') +
labs(y = "CDF (% pop.)", x = "Usage (% trips)") +
scale_x_continuous(limits = c(0,100), expand = c(0.1, 0)) +
theme_bw() +
theme(text=element_text(size=11,  family="Helvetica"), axis.text.y = element_text(size=9), axis.text.x = element_text(size=9), plot.background = element_rect(fill = "#ffffff", color = NA, size = 0.33), plot.margin = margin(t = 12, r = 16, b = 4, l = 48, unit = "points"))
# Specify viewport width for the map.
wid = 0.675
output_figure_path <- file.path(main_path, "output", "figure_2.pdf")
pdf(file = output_figure_path, width = 9, height = 5)
# Define the top viewport for the grid layout.
# This sets up a 2x2 grid layout.
top_vp <- viewport(x = 0, y = 0, width = 1, height = 1, layout = grid.layout(nrow = 2,ncol = 2,widths=c(1-wid, wid), heights=c(0.33, 0.66)), just = c("left", "bottom"))
pushViewport(top_vp)
print(usage_msas_barchart,vp = viewport(layout.pos.col = 1, layout.pos.row=2))
print(cdf_plot,vp = viewport(layout.pos.col = 1, layout.pos.row=1))
popViewport()
# Define the left viewport for the grid layout.
# This sets up a 3x1 grid layout for the map and legend.
left_vp_1 <- viewport(x = 1-wid, y = 0, width = wid, height = 1, layout = grid.layout(nrow = 3,ncol = 1,heights=c(.85,0,.15)), just = c("left", "bottom"))
pushViewport(left_vp_1)
print(us_map_usage,vp = viewport(layout.pos.col = 1, layout.pos.row=1))
print(as_ggplot(legend),vp = viewport(layout.pos.col = 1, layout.pos.row=2))
popViewport()
# Define a small viewport for the legend.
small_vp <- viewport(x = (1-wid) + 0.015, y = 0, width = wid, height = 1, layout = grid.layout(nrow = 3,ncol = 2, widths = c(0.5,0.5), heights=c(.6,.39,.01)), just = c("left", "bottom"))
pushViewport(small_vp)
print(us_map_usage_legend,vp = viewport(layout.pos.col = 1, layout.pos.row=2))
popViewport()
# Label the visualizations A, B, C
grid.text("b", x = (1-wid) + 0.025, y = .965, gp = gpar(fontfamily="Helvetica", fontface="bold"))
grid.text("a", x = 0.04, y = .965, gp = gpar(fontfamily="Helvetica", fontface="bold"))
grid.text("c", x = 0.04, y = 0.66 - 0.025, gp = gpar(fontfamily="Helvetica", fontface="bold"))
dev.off()
main_path <- "/Users/arianna/Dropbox (Personal)/SenseableCityLab/15_minute_city/_git/15-Minute-City/replication"  # User should replace this with the path to the 'replication' folder
# Set working directory to main path
setwd(main_path)
# Read the datasets.
data_path <- file.path(main_path, "data", "clean", "outcomes_blckgrp_clean_allpois_popweighted.csv")
data_urb_path <- file.path(main_path, "data", "clean", "outcomes_urb_clean_allpois_popweighted.csv")
data <- read.csv(data_path)
data_urb <- read.csv(data_urb_path)
# Rename variables
data  <- data %>% dplyr::rename(
density_hu_acre = epa_D1A,
total_pop = idx_total_population,
density_pop_acre = epa_D1B,
median_hh_income = cs_b19013e1,
density_road = epa_D3A
)
data_urb  <- data_urb %>% dplyr::rename(
density_hu_acre = epa_D1A,
total_pop = idx_total_population,
density_pop_acre = epa_D1B,
median_hh_income = cs_b19013e1,
density_road = epa_D3A
)
# Compute percent with education BA+
data$pct_ed_ba_plus <- 100 * (data$cs_b15003e22 + data$cs_b15003e23 + data$cs_b15003e24 + data$cs_b15003e25) / data$cs_b15003e1
data_urb$pct_ed_ba_plus <- 100 * (data_urb$cs_b15003e22 + data_urb$cs_b15003e23 + data_urb$cs_b15003e24 + data_urb$cs_b15003e25) / data_urb$cs_b15003e1
# Compute the median usage weighted by CBG population
round(reldist::wtd.quantile(data$usage_pct_all_cats_home_bg_based, 0.5, weight = data$total_pop),2)
round(modi::weighted.quantile(data$usage_pct_all_cats_home_bg_based, data$total_pop, prob = 0.5),2)
round(sum(data$usage_pct_all_cats_home_bg_based<=0.5)/nrow(data),2)
n_distinct(data$urb)
# Format variables (CBG-level data)
data$city <- as.factor(data$urb)
data$bg_geoid <- as.factor(data$bg_geoid)
data$census_tract <- as.factor(substr(data$bg_geoid,1,11))
data$county_id <- as.factor(substr(data$bg_geoid,1,5))
data <- data %>% dplyr::rename(epa_transit_freq_sqm=epa_D4D)
# Create additional transformations, i.e. percentages and logs for controls (CBG-level)
data <- data %>% mutate(
median_hh_income_pct = percent_rank(median_hh_income),
pct_white = 100 * cs_share_white,
pop_density_log = log1p(density_pop_acre),
hu_density_log = log1p(density_hu_acre),
transit_stops_density_log = log1p(doc_transit_density_acre),
median_income_log = log1p(median_hh_income)
)
# Format variables (URB-level data)
data_urb$city <- as.factor(data_urb$urb)
data_urb <- data_urb %>% dplyr::rename(epa_transit_freq_sqm=epa_D4D)
# Create additional transformations, i.e. percentages and logs for controls (URB-level)
data_urb <- data_urb %>% mutate(
median_hh_income_pct = percent_rank(median_hh_income),
pct_white = 100 * cs_share_white,
pop_density_log = log1p(density_pop_acre),
hu_density_log = log1p(density_hu_acre),
transit_stops_density_log = log1p(replace_na(doc_transit_density_acre,0)),
median_income_log = log1p(median_hh_income)
)
data$usage_pct_all_cats_home_bg_based <- 100 * data$usage_pct_all_cats_home_bg_based
data$access_idx_crosscity_wt <- 100 * data$access_idx_crosscity_wt
data_urb$usage_pct_all_cats_home_bg_based <- 100 * data_urb$usage_pct_all_cats_home_bg_based
data_urb$access_idx_crosscity_wt <- 100 * data_urb$access_idx_crosscity_wt
# Run main regressions, first without controls then two more, adding controls  (CBG level)
est_c0 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt | city | 0 | county, data=data)
est_c1 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt + pop_density_log + median_income_log + pct_ed_ba_plus + pct_white| city | 0 | county, data=data)
est_c4 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt + pop_density_log + median_income_log + pct_ed_ba_plus + pct_white + epa_transit_freq_sqm + avg_dist_work| city | 0 | county, data=data)
# Run main regressions, first without controls then two more, adding controls  (URB level)
est_ur0 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt, data=data_urb)
est_ur1 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt + pop_density_log + median_income_log + pct_ed_ba_plus + pct_white, data=data_urb)
est_ur4 <- felm(usage_pct_all_cats_home_bg_based ~ access_idx_crosscity_wt + pop_density_log + median_income_log + pct_ed_ba_plus + pct_white + epa_transit_freq_sqm + avg_dist_work, data=data_urb)
# Create the table with regression results
table_str <- stargazer(est_c0, est_c1, est_c4, est_ur0, est_ur1, est_ur4,
type='latex',
report=('vc*p'),
covariate.labels = c(
"15-minute Access",
"Pop Density Log",
"Median Income Log",
"\\% Education: BA +",
"\\% White",
"Transit Frequency (per sq. mi)",
"Average Commute (mi)"
),
add.lines=list(c("Urban Area FE", "\\checkmark", "\\checkmark", "\\checkmark","", "", "")),
dep.var.labels = c("15-minute Usage", "15-minute Access"),
column.labels = c("Across CBGs", "Across Urban Areas"),
omit.stat=c("f", "ser", "adj.rsq"),
omit=c("Constant"),
column.separate=c(4,4),
dep.var.caption=c("Dependent Variable (between 0 and 100)")
)
write(gsub("p = 0.000[0-9]*", "p $<$ 0.001",paste(table_str,collapse="\n")), file="output/TableS4.tex")
